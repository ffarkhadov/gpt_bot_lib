"""
report_scripts/p_campain_fin_1.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
–ó–∞–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü F ¬´–†–∞—Å—Ö–æ–¥—ã –Ω–∞ —Ä–µ–∫–ª–∞–º—É¬ª –≤ unit-day
–ø–æ –¥–∞–Ω–Ω—ã–º Performance API Ozon.

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã run() –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç core/tasks/report_runner:

run(
    gs_cred            = '/path/sa.json',
    spread_id          = '1AbCdE‚Ä¶',
    sheet_main         = 'unit-day',
    perf_client_id     = '‚Ä¶@advertising.performance.ozon.ru',
    perf_client_secret = 'xxxxxxxx',
    days               = 7         # –≥–ª—É–±–∏–Ω–∞, –ø–æ-—É–º–æ–ª—á–∞–Ω–∏—é
)
"""
from __future__ import annotations

import io
import time
import zipfile
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from typing import Callable

import pandas as pd
import requests
import gspread
from google.oauth2.service_account import Credentials

API = "https://api-performance.ozon.ru"
UTC = timezone.utc


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def log(msg: str):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)


def sleep_progress(sec: int):
    for _ in range(sec):
        time.sleep(1)
        print(".", end="", flush=True)
    print()


def get_token(session: requests.Session, cid: str, secret: str) -> tuple[str, datetime]:
    r = session.post(
        f"{API}/api/client/token",
        json={"client_id": cid, "client_secret": secret, "grant_type": "client_credentials"},
        headers={"Content-Type": "application/json", "Accept": "application/json"},
        timeout=None,
    )
    r.raise_for_status()
    token = r.json()["access_token"]
    log(f"token OK ({token[:10]}‚Ä¶)")
    return token, datetime.now(UTC)


def ensure_token(session: requests.Session,
                 token_time: datetime,
                 cid: str,
                 secret: str,
                 headers_cb: Callable[[dict], None]) -> datetime:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–∫–µ–Ω, –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ >25 –º–∏–Ω."""
    if (datetime.now(UTC) - token_time).total_seconds() <= 1500:
        return token_time
    new, t = get_token(session, cid, secret)
    headers_cb({"Authorization": f"Bearer {new}"})
    return t


def chunk(lst: list, n: int = 10):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ —Ä–∞–±–æ—Ç–∞ —Å Performance API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def fetch_campaigns(session: requests.Session, headers: dict) -> list[str]:
    r = session.get(f"{API}/api/client/campaign", headers=headers, timeout=None)
    r.raise_for_status()
    good = {"CAMPAIGN_STATE_RUNNING", "CAMPAIGN_STATE_STOPPED", "CAMPAIGN_STATE_INACTIVE"}
    ids = [str(c["id"]) for c in r.json()["list"] if c.get("state") in good]
    log(f"campaigns: {ids}")
    return ids


def post_statistics(session: requests.Session,
                    headers: dict,
                    camp_ids: list[str],
                    date_from: str,
                    date_to: str) -> str:
    while True:
        r = session.post(
            f"{API}/api/client/statistics",
            headers=headers,
            json={"campaigns": camp_ids,
                  "dateFrom": date_from,
                  "dateTo":   date_to,
                  "groupBy":  "DATE"},
            timeout=None)
        if r.status_code == 429:
            log("‚ö†Ô∏è 429 ‚Äì –∂–¥—ë–º 70 —Å")
            sleep_progress(70)
            continue
        r.raise_for_status()
        return r.json()["UUID"]


def wait_uuid(session: requests.Session,
              uuid: str,
              headers_fn: Callable[[], dict],
              refresh_token: Callable[[], None]):
    url = f"{API}/api/client/statistics/{uuid}"
    while True:
        refresh_token()
        r = session.get(url, headers=headers_fn(), timeout=None)
        if r.status_code == 429:
            log("‚ö†Ô∏è 429 UUID-poll ‚Äì –∂–¥—ë–º 70 —Å")
            sleep_progress(70)
            continue
        r.raise_for_status()
        state = r.json().get("state")
        log(f"uuid {uuid} ‚Üí {state}")
        if state == "OK":
            return
        if state == "FAILED":
            raise RuntimeError(f"uuid {uuid} FAILED")
        time.sleep(60)


def download_zip(session: requests.Session, headers: dict, uuid: str) -> bytes:
    while True:
        r = session.get(f"{API}/api/client/statistics/report",
                        headers=headers, params={"UUID": uuid}, timeout=None)
        if r.status_code == 429:
            log("‚ö†Ô∏è 429 ZIP ‚Äì –∂–¥—ë–º 70 —Å")
            sleep_progress(70)
            continue
        r.raise_for_status()
        if "application/zip" not in r.headers.get("Content-Type", ""):
            raise RuntimeError("–Ω–µ ZIP")
        return r.content


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CSV ‚Üí DataFrame ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∂—ë—Å—Ç–∫–æ –æ–∂–∏–¥–∞–ª —Ä—É—Å—Å–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏;
# –¥–æ–±–∞–≤–ª—è–µ–º fallback-–Ω–∞–±–æ—Ä—ã ¬´Day / Ad spend, ‚ÇΩ incl. VAT¬ª –∏ –¥—Ä.
USECOL_SETS = [
    ["–î–µ–Ω—å", "sku", "–†–∞—Å—Ö–æ–¥, ‚ÇΩ, —Å –ù–î–°"],
    ["Day", "sku", "Spend, ‚ÇΩ incl. VAT"],
    ["Day", "sku", "–†–∞—Å—Ö–æ–¥, ‚ÇΩ, —Å –ù–î–°"],
    ["–î–µ–Ω—å", "sku", "Spend, ‚ÇΩ incl. VAT"],
]


def read_csv_flexible(buf) -> pd.DataFrame | None:
    for cols in USECOL_SETS:
        try:
            df = pd.read_csv(buf, sep=";", skiprows=1, usecols=cols)
            df.columns = ["date", "sku", "rub"]
            return df
        except ValueError:
            continue
    return None


def parse_zip(data: bytes) -> pd.DataFrame:
    dfs = []
    with zipfile.ZipFile(io.BytesIO(data)) as zf:
        for fn in zf.namelist():
            if not fn.lower().endswith((".csv", ".txt")):
                continue
            df = read_csv_flexible(io.TextIOWrapper(zf.open(fn), "utf-8"))
            if df is None:
                continue
            df = df[df["date"] != "–í—Å–µ–≥–æ"]
            df["sku"] = pd.to_numeric(df["sku"], errors="coerce").dropna().astype(int)
            df["rub"] = pd.to_numeric(df["rub"].astype(str).str.replace(",", "."),
                                      errors="coerce").fillna(0.0)
            dfs.append(df)

    if not dfs:
        return pd.DataFrame(columns=["date", "sku", "rub"])

    out = pd.concat(dfs, ignore_index=True)
    out = out.groupby(["date", "sku"], as_index=False)["rub"].sum()
    return out


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –∑–∞–ø–∏—Å—å –≤ Google Sheets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def write_sheet(gs_cred: str, spread_id: str, sheet: str, df: pd.DataFrame):
    creds = Credentials.from_service_account_file(
        gs_cred,
        scopes=["https://spreadsheets.google.com/feeds",
                "https://www.googleapis.com/auth/drive"]
    )
    ws = gspread.authorize(creds).open_by_key(spread_id).worksheet(sheet)
    rows = ws.get_all_values()
    if not rows:
        log("‚ö†Ô∏è –õ–∏—Å—Ç –ø—É—Å—Ç, –Ω–∏—á–µ–≥–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å")
        return

    head = rows[0]
    try:
        col_date = head.index("–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
        col_sku  = head.index("SKU")
    except ValueError as e:
        raise RuntimeError("unit-day –±–µ–∑ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫") from e

    # index ‚Üí key
    sheet_map = defaultdict(list)
    for i, r in enumerate(rows[1:], start=2):
        key = (r[col_date].split(" ")[0], str(r[col_sku]))
        sheet_map[key].append(i)

    updates = []
    for _, r in df.iterrows():
        for row_idx in sheet_map.get((r["date"], str(r["sku"])), []):
            updates.append({"range": f"F{row_idx}", "values": [[round(r["rub"], 2)]]})

    if updates:
        ws.batch_update(updates)
        log(f"üü¢ –ó–∞–ø–∏—Å–∞–Ω–æ {len(updates)} —è—á–µ–µ–∫")
    else:
        log("‚ÑπÔ∏è –°–æ–≤–ø–∞–¥–µ–Ω–∏–π (date+sku) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ run() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def run(
    *,
    gs_cred: str,
    spread_id: str,
    sheet_main: str = "unit-day",
    perf_client_id: str,
    perf_client_secret: str,
    days: int = 7,
):
    session = requests.Session()

    token, token_time = get_token(session, perf_client_id, perf_client_secret)
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Authorization": f"Bearer {token}",
    }

    # —Ñ—É–Ω–∫—Ü–∏—è-–∑–∞–º—ã–∫–∞–Ω–∏–µ –¥–ª—è ¬´–ø—Ä–æ–∫–∏–¥—ã–≤–∞–Ω–∏—è¬ª –Ω–æ–≤—ã—Ö header‚Äô–æ–≤
    def set_headers(d: dict):
        headers.update(d)

    def hdr() -> dict:
        return headers

    # 1. –∫–∞–º–ø–∞–Ω–∏–∏
    cids = fetch_campaigns(session, hdr())

    # 2. –¥–∞—Ç—ã –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    msk_now = datetime.now(UTC) + timedelta(hours=3)
    date_to = msk_now.date()
    date_from = (msk_now - timedelta(days=days)).date()
    df_str, dt_str = date_from.strftime("%Y-%m-%d"), date_to.strftime("%Y-%m-%d")

    # 3. —Å–æ–±–∏—Ä–∞–µ–º UUID
    uuids: list[str] = []
    for ch in chunk(cids, 10):  # 10 –∫–∞–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º
        uuid = post_statistics(session, hdr(), ch, df_str, dt_str)
        log(f"uuid {uuid} OK ‚Üí wait")
        wait_uuid(
            session,
            uuid,
            hdr,
            lambda: set_headers(
                {"Authorization": f"Bearer {get_token(session, perf_client_id, perf_client_secret)[0]}"}
            ),
        )
        uuids.append(uuid)
        time.sleep(1)  # –º—è–≥–∫–∏–π RPS-limit

    # 4. —Å–∫–∞—á–∏–≤–∞–µ–º ZIP-—ã, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º
    df_total = pd.DataFrame(columns=["date", "sku", "rub"])
    for u in uuids:
        df_total = pd.concat(
            [df_total, parse_zip(download_zip(session, hdr(), u))],
            ignore_index=True,
        )

    if df_total.empty:
        log("‚ÑπÔ∏è –ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ ‚Üí –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return

    # 5. Google Sheets
    write_sheet(gs_cred, spread_id, sheet_main, df_total)
    log("‚úÖ p_campain_fin_1 DONE")
